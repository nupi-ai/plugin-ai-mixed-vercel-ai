apiVersion: nap.nupi.ai/v1alpha1
kind: Plugin
type: adapter
metadata:
  name: Nupi AI Mixed (Vercel AI SDK)
  namespace: ai.nupi
  slug: ai-mixed-vercel-ai
  description: Universal AI adapter supporting multiple providers via Vercel AI SDK
  version: 1.0.0
spec:
  slot: ai
  homepage: https://github.com/nupi-ai/plugin-ai-mixed-vercel-ai
  compatibility:
    nupi: ">=0.0.0-dev"
  entrypoint:
    runtime: js
    command: ./index.js
    args: []
    transport: process
    listenEnv: NUPI_ADAPTER_LISTEN_ADDR
    readyTimeout: 30s
    shutdownTimeout: 15s
  options:
    tasks:
      type: object
      description: >
        Per-event-type model configuration. Each key is an event type
        (user_intent, session_output, history_summary, clarification,
        memory_flush, scheduled_task, session_slug, onboarding) and each
        value is a complete config block with provider, model, and optional
        api_key, base_url, max_tokens, temperature. No inheritance between
        tasks â€” each must be self-contained.
      example:
        user_intent:
          provider: anthropic
          model: claude-sonnet-4-5-20250929
          api_key: sk-ant-...
          max_tokens: 2048
          temperature: 0.7
        history_summary:
          provider: openai
          model: gpt-4o-mini
          api_key: sk-...
          max_tokens: 1024
          temperature: 0.3
    language:
      type: string
      default: client
      description: >
        Language mode for AI responses. "client" (default) reads the language
        from the nupi.lang.english request metadata propagated by the daemon;
        falls back to auto-detect if no metadata is present. "auto" instructs the
        AI to detect the user's language and respond in the same language. A specific
        ISO 639-1 code (e.g. "en", "de") forces the AI to always respond in that
        language regardless of input.
  telemetry:
    stdout: true
    stderr: true
