apiVersion: nap.nupi.ai/v1alpha1
kind: Plugin
type: adapter
metadata:
  name: Nupi AI Mixed (Vercel AI SDK)
  catalog: ai.nupi
  slug: ai-mixed-vercel-ai
  description: Universal AI adapter supporting multiple providers via Vercel AI SDK
  version: 1.0.0
spec:
  slot: ai
  homepage: https://github.com/nupi-ai/plugin-ai-mixed-vercel-ai
  compatibility:
    nupi: ">=0.0.0-dev"
  entrypoint:
    runtime: js
    command: ./index.js
    args: []
    transport: process
    listenEnv: NUPI_ADAPTER_LISTEN_ADDR
    readyTimeout: 30s
    shutdownTimeout: 15s
  options:
    provider:
      type: string
      default: openai
      description: AI provider name (openai, anthropic, google, ollama, or any openai-compatible)
    model:
      type: string
      default: gpt-4o-mini
      description: Model identifier (provider-specific)
    api_key:
      type: string
      description: API key for the provider (not needed for Ollama)
    base_url:
      type: string
      description: Custom base URL (for openai-compatible or Ollama)
    max_tokens:
      type: integer
      default: 1024
      description: Maximum tokens in response
    temperature:
      type: number
      default: 0.7
      description: Sampling temperature (0.0-2.0)
    language:
      type: string
      default: client
      description: >
        Language mode for AI responses. "client" (default) reads the language
        from the nupi.lang.english request metadata propagated by the daemon;
        falls back to auto-detect if no metadata is present. "auto" instructs the
        AI to detect the user's language and respond in the same language. A specific
        ISO 639-1 code (e.g. "en", "de") forces the AI to always respond in that
        language regardless of input.
  telemetry:
    stdout: true
    stderr: true
